# マルチモーダル顧客対応 AI エージェント（Mastra） - 実践的アプリケーション仕様

## 1. プロジェクト概要

本プロジェクトは、2025 年の AI エージェントの進化（マルチモーダル処理、長期記憶、複雑な意思決定、専門知識）を意識し、クライアントが将来的に求めるであろう高度な能力をデモンストレーションするものです。具体的には、**カスタマーサービスにおける問い合わせ対応を高度に自動化する AI エージェント**を構築します。テキストチャットだけでなく、音声入力（顧客の声のトーン分析）や画像（製品の破損状況写真）を理解し、顧客の状況を総合的に判断して対応します。長期記憶機能により、過去の顧客とのやり取りや購入履歴を考慮したパーソナライズされたサポートを提供します。

## 2. プロジェクトゴール

- カスタマーサービスにおける問い合わせ対応の高度な自動化
- テキスト、音声、画像のマルチモーダル入力への対応
- 長期記憶機能によるパーソナライズされた顧客サポートの提供
- 外部システム（CRM、EC サイト）連携のシミュレーション

## 3. 主要機能

### 3.1. マルチモーダル入力処理

- **テキスト入力:**
  - 通常のチャットインターフェースからのテキスト入力。
  - 顧客の質問や要望を直接受け付ける。
- **音声入力:**
  - ブラウザまたはマイクからの音声入力をリアルタイムでテキストに変換。
  - 変換されたテキストに対し、簡易的な感情分析（ポジティブ/ネガティブ/中立）を実施。
  - 例：「声のトーンからお困りの様子がうかがえます。」のような応答に利用。
- **画像入力:**
  - 顧客が製品の破損状況や、問い合わせに関連するスクリーンショットなどをアップロードできる機能。
  - アップロードされた画像を解析し、問題の種類や状況を特定。
  - 例：「画像の破損状況から判断すると、〇〇部品の交換が必要かと思われます。」のような応答に利用。

### 3.2. 長期記憶と状況認識

- **Mastra のメモリ機能（セマンティックメモリ）活用:**
  - 顧客 ID をキーとして、以下の情報を永続的に保存し、必要に応じて参照。
    - 過去の問い合わせ履歴（日時、内容、解決策、担当エージェントなど）
    - 購入履歴（製品名、購入日時、価格、配送状況など）
    - 基本情報（氏名、住所、連絡先など）
  - 現在の対話において、長期記憶から得られた情報を考慮し、より文脈に沿った適切な応答を生成。

### 3.3. パーソナライズされた応答

- 長期記憶から得られた顧客の過去の履歴や購買情報に基づき、**一人ひとりに合わせた個別具体的な情報提供や提案**を行う。
- 例：「〇〇様、以前ご購入いただいた △△ 製品についてですね。承知いたしました。」「以前お話しされた内容を考慮し、最適なプランをご提案します。」

### 3.4. 外部ツール連携シミュレーション

- **モック API サーバーによる CRM/EC サイト連携の模倣:**
  - 顧客情報取得 API: 顧客 ID を基に、氏名、住所、連絡先、過去の問い合わせ履歴、購入履歴などを返す。
  - 注文履歴更新 API: 注文ステータスの更新（例：配送状況の確認）や、キャンセル、返品処理のシミュレーション。
  - Mastra エージェントが**Function Calling**によりこれらの API を呼び出し、リアルタイムで情報を取得・更新する挙動をデモンストレーション。

### 3.5. 問題解決とエスカレーション

- **定型的な問い合わせの自動解決:**
  - FAQ に基づく回答、製品情報提供、アカウント情報の確認など、事前に定義されたシナリオに基づく問い合わせは AI エージェントが自動で解決。
- **複雑な問題や感情的な問い合わせのエスカレーション:**
  - AI エージェントが解決困難と判断した、あるいは顧客が感情的になっていると判断した場合、人間のオペレーターへのエスカレーションを提案。
  - エスカレーション時には、これまでの対話履歴や取得した情報をオペレーターに引き継ぐシミュレーション。

## 4. 技術スタック

- **フレームワーク:** TypeScript (Mastra)
- **LLM:** OpenAI GPT-4o (マルチモーダル対応)
- **フロントエンド:** Next.js / React (Mastra と親和性が高い Web 開発環境)
- **音声認識:**
  - Web Speech API (ブラウザベース - 簡易的なデモ向け)
  - または Google Cloud Speech-to-Text API (より高精度な認識が必要な場合、Node.js バックエンド経由)
- **画像認識:**
  - OpenAI GPT-4V (Mastra 経由での利用を想定)
  - または Google Cloud Vision AI API (より詳細な物体検出やテキスト認識が必要な場合)
- **感情分析:**
  - 簡易的な感情辞書ベースの実装 (キーワードマッチング、スコアリング)
  - または既存の NLP ライブラリ (例: `natural` for Node.js - 形態素解析や感情語彙辞書を活用)
- **メモリ:** Mastra の組み込みメモリ機能 (LibSQL, Postgres などをバックエンドに選択可能)
- **外部連携:** モック API サーバー (Node.js/Express で簡易実装) - CRM/EC サイトのデータ（顧客 ID、購入履歴、問い合わせ履歴）をシミュレート

## 5. 期待される成果と評価指標

### 5.1. 定量的指標

- **問い合わせ解決率:** AI エージェントが単独で顧客の問い合わせを解決できた割合。
- **平均応答時間:** 顧客の問い合わせから AI エージェントが最初の応答を返すまでの平均時間。
- **顧客満足度スコア:** (簡易的なアンケート結果をシミュレート) 例: 「今回の対応にご満足いただけましたか？ (はい/いいえ)」

### 5.2. 定性的指標

- **マルチモーダル入力への対応の適切性:** テキスト、音声、画像それぞれの入力に対して、AI エージェントが適切に理解し、関連性の高い応答を生成できているか。
- **パーソナライズされた応答の質:** 長期記憶を活用し、顧客の過去の履歴に基づいた個別具体的な情報提供や提案が、自然かつ適切に行われているか。
- **問題解決のロジック:** 問い合わせ内容に対する解決策の提示が論理的で、かつ正確であるか。
- **エスカレーション判断の適切性:** 人間による介入が必要なケースを適切に判断し、スムーズなエスカレーション提案が行われているか。

## 6. 実装ステップ（詳細）

### 6.1. ステップ 1: プロジェクトの初期設定と Mastra の導入

1.  **Next.js プロジェクトのセットアップ:**
    ```bash
    npx create-next-app@latest your-customer-agent --typescript --tailwind --eslint
    ```
    コマンドで新しい Next.js プロジェクトを作成。
2.  **Mastra の導入と初期化:**
    - Mastra の公式ドキュメントに従い、プロジェクトに Mastra をインストールし、初期設定を行う。
    ```bash
    npm install @mastragpt/core @mastragpt/nextjs
    ```
    - Mastra の API キー設定（環境変数 `.env.local` に `MASTRA_API_KEY=your_key`）。
    - Mastra エージェントの基本的な設定ファイル (`src/lib/mastra.ts` など) を作成。

### 6.2. ステップ 2: マルチモーダル入力 UI の設計と実装

1.  **チャットインターフェースの基盤構築:**
    - `src/app/page.tsx` または `src/components/ChatWindow.tsx` に基本的なチャット UI（入力フィールド、送信ボタン、メッセージ表示エリア）を React コンポーネントとして実装。
    - Tailwind CSS を利用してモダンなデザインを適用。
2.  **音声入力ボタンの実装:**
    - マイクアイコンのボタンを配置。
    - クリック時に Web Speech API を起動し、音声入力を開始/停止するロジックを実装。
    - 音声認識結果をテキスト入力フィールドに反映させる。
    - **感情分析の準備:** 音声入力と同時に、簡易的な感情辞書（例: 「困った」「ありがとう」などのキーワードと感情スコアを紐付けた JSON ファイル）を用いて感情を推定するロジックの骨子を作成。
3.  **画像アップロード機能の実装:**
    - ファイル選択ボタンを配置し、`input type="file" accept="image/*"` を利用。
    - 選択された画像をプレビュー表示し、base64 エンコードして Mastra エージェントに送信できるよう準備。
    - 画像表示のためのコンポーネントも作成。

### 6.3. ステップ 3: Mastra エージェントの定義とマルチモーダル処理の統合

1.  **Mastra エージェントの基本定義:**
    - `src/mastra-agents/customer-agent.ts` のようなファイルで Mastra エージェントを定義。
    - 初期プロンプトとして、カスタマーサービスの AI エージェントとしての役割（丁寧な対応、情報提供、問題解決）を設定。
2.  **マルチモーダル入力の Mastra への受け渡し:**
    - Next.js の API ルート (`src/app/api/chat/route.ts` など) を通じて、クライアントからのテキスト、音声認識結果（テキスト＋感情）、画像データ（base64）を Mastra エージェントに送信。
    - Mastra エージェントはこれらの入力タイプを識別し、適切な処理フローに分岐させる。
3.  **音声・画像認識 API の Mastra ツールとしての組み込み:**
    - **OpenAI GPT-4o/4V の利用:** Mastra のエージェント内で、OpenAI のマルチモーダル API を直接呼び出す`tool`を定義。
      - 画像データを受け取った際に、`gpt-4-turbo-2024-04-09`などのモデル（GPT-4V 相当）に画像を送り、その内容を解析して応答を生成するように設定。
      - 音声認識結果（テキスト）と感情データを受け取った際も同様に、文脈と感情を考慮した応答を生成。
    - **Google Cloud API の利用 (オプション):**
      - もし Google Cloud Speech-to-Text や Vision AI を使用する場合、Node.js バックエンドでこれらの API を呼び出す関数を作成し、Mastra エージェントが Function Calling でそれらの関数を呼び出すように設定。

### 6.4. ステップ 4: 長期記憶の実装

1.  **Mastra のメモリ機能の活用:**
    - Mastra エージェントの設定ファイル内で、`memory`オプションを有効にし、`LibSQL`または`Postgres`などのバックエンドを設定。
    - 顧客 ID（セッション ID やログインしているユーザー ID など）をキーとして、各顧客の対話履歴、購入履歴、基本情報をメモリに保存するロジックを Mastra ワークフロー内で定義。
      - 例: 顧客が初回の問い合わせの場合、名前や連絡先を尋ね、メモリに保存する。
      - 購入履歴や過去の問い合わせは、モック API から取得した際にメモリに格納する。
2.  **メモリからの情報参照:**
    - 新しい問い合わせがあった際、Mastra エージェントはまずメモリから該当顧客の過去の情報を取得。
    - 取得した情報を基に、プロンプトに含めることで、よりパーソナライズされた応答を生成させる。

### 6.5. ステップ 5: モック CRM/EC 連携の構築と Function Calling

1.  **モック API サーバーの作成:**
    - Node.js と Express を使って、簡易的な RESTful API サーバーを構築 (`src/api-server/index.ts` など)。
    - 以下のエンドポイントを実装:
      - `GET /customers/:customerId`: 顧客 ID に基づいて顧客情報（氏名、住所、連絡先、過去の問い合わせ履歴、購入履歴）を JSON 形式で返す。
      - `GET /orders/:orderId`: 注文 ID に基づいて注文詳細と配送状況を返す。
      - `POST /orders/update-status`: 注文ステータスを更新する（シミュレーション）。
    - サンプルデータ（JSON ファイルやインメモリの JavaScript オブジェクト）を用意し、それらを返すように設定。
2.  **Mastra エージェントからの Function Calling:**
    - Mastra エージェント内で、モック API サーバーのエンドポイントを呼び出す`tool`（Function Calling）を定義。
    - 例: 顧客が「注文の状況を知りたい」と発言した場合、Mastra エージェントが Function Calling を使って`GET /orders/:orderId`を呼び出し、その結果を基に応答を生成。
    - 顧客 ID が必要な問い合わせの場合、Mastra がユーザーに顧客 ID を尋ね、取得後に Function Calling を行うようにワークフローを設計。

### 6.6. ステップ 6: デモと評価

1.  **シナリオの準備:**
    - 複数の顧客対応シナリオを作成（例: 製品の破損問い合わせ、注文状況確認、アカウント情報変更、複雑な技術サポートなど）。
    - 各シナリオで、テキスト、音声、画像入力を組み合わせたパターンを用意。
2.  **デモの実施:**
    - 作成したシナリオに沿って、AI エージェントとの対話デモを実施。
    - マルチモーダル入力への対応、パーソナライズされた応答、長期記憶の活用、外部連携の動作を確認。
3.  **評価指標の提示:**
    - 上記「期待される成果と評価指標」に基づき、デモ結果を評価。
    - 特に定性的な評価は、デモ中に得られた具体的な応答例を挙げて評価理由を説明。
    - 簡易的な顧客満足度アンケートをデモ終了時に表示し、結果をシミュレート。

### 6.7. ステップ 7: ドキュメンテーション

1.  **GitHub リポジトリの作成:**
    - プロジェクトのコードを GitHub リポジトリにプッシュ。
2.  **README.md の作成:**
    - 以下の項目を詳細に記述:
      - **プロジェクトの目的:** 本アプリケーションが解決しようとする課題と、提供する価値。
      - **技術スタック:** 使用している全ての技術（Mastra, Next.js, GPT-4o など）。
      - **アーキテクチャ概要:** アプリケーションの各コンポーネント（フロントエンド、Mastra エージェント、モック API サーバー、LLM）がどのように連携するかを図で示す。
      - **主要機能の詳細:** 各機能の具体的な説明と、どのように実現されているか。
      - **実行方法:** プロジェクトのクローン、依存関係のインストール、環境変数の設定、アプリケーションの起動方法など、詳細な手順を記載。
      - **デモ動画へのリンク:** デモの様子を録画した動画（YouTube など）へのリンクを貼る。
      - **期待される成果と評価:** 定量的・定性的な評価指標に基づいたデモ結果のまとめ。
      - **今後の展望:** 本プロジェクトのさらなる発展の可能性について記述。

---
